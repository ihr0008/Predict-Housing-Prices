{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What was I Working On when I Quit:\n",
    " - Pipeline is working! \n",
    " - Basic tested a bunch of models, XGBRegressor seemed to do best with almost no changes from default\n",
    " - Add polynomial features and see how that works\n",
    "- im using this link to learn about preprocessing https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Beginning\n",
    "## Run all cells below until the section of not required to run cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import a bunch of stuff thats used later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingRegressor\n",
    "from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - House_data was previously cleaned in R in the following ways:\n",
    " - Dropping columns that were highly correlated with others (>0.85)\n",
    " - Dropping columns with more lots of NAs (>90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "house_data = pd.read_csv(\"C:/Users/isaac/Desktop/Data Science Stuff/Kaggle Comp Housing Prices/clean_train.csv\")\n",
    "house_data.drop(['Unnamed: 0', 'Id'], axis = 1,inplace = True)\n",
    "test_data = pd.read_csv(\"C:/Users/isaac/Desktop/Data Science Stuff/Kaggle Comp Housing Prices/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign y and X variables\n",
    "y = house_data.SalePrice\n",
    "X = house_data.drop(['SalePrice'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Global Random Seed\n",
    "np.random.seed(213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1382fd37160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Y has a few crazy outliers\n",
    "plt = house_data.SalePrice.hist(cumulative=False, density=1, bins=100)\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pipeline the Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List column names for pipe again\n",
    "num_cols = [\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"GrLivArea\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\",\"Fireplaces\",\"GarageCars\",\"GarageArea\",\"WoodDeckSF\",\"OpenPorchSF\"]\n",
    "ord_cols = [\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"HeatingQC\",\"KitchenQual\", \"FireplaceQu\"]\n",
    "OH_cols = list(set(X.columns) - set(num_cols) - set(ord_cols))\n",
    "all_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============ Pipeline Entire Data preprocessing =================#\n",
    "\n",
    "class NominalFixer(BaseEstimator, TransformerMixin): #Create Sklearn style transformer for ordinal data\n",
    "\n",
    "    def __init__(self):\n",
    "        pass  # e.g. pass in a column name to extract\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        def orderizer(df, order_cats = ['missing', 'Po', 'Fa', 'TA', 'Gd','Ex']):\n",
    "            for col in df.columns:\n",
    "                cat = pd.Categorical(df[col],\n",
    "                                    categories = order_cats,\n",
    "                                     ordered = True)\n",
    "                cat = cat.fillna('missing')\n",
    "                labels, unique = pd.factorize(cat, sort=True)\n",
    "                df[col] = labels\n",
    "        orderizer(X)\n",
    "        return X  \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "class Stringer(BaseEstimator, TransformerMixin): #Create Sklearn style transformer for turing OH columns into strings\n",
    "\n",
    "    def __init__(self):\n",
    "        pass  # e.g. pass in a column name to extract\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.astype(str)\n",
    "        return X  \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('binner', KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='kmeans')),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "ord_pipeline = Pipeline([\n",
    "        ('orderizer', NominalFixer())\n",
    "    ])\n",
    "\n",
    "OH_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"constant\")),\n",
    "        ('stringer', Stringer()),\n",
    "        ('OH_enc', OneHotEncoder(sparse = False, handle_unknown = 'ignore')),\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Pipeline that combines the pipelines above and transformers specified columns (Outputs an array)\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_cols),\n",
    "        (\"OH\", OH_pipeline, OH_cols),\n",
    "        (\"ord\", ord_pipeline, ord_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers and Reselect X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Isolation Forest to detect outliers\n",
    "isofor = IsolationForest(random_state = 213)\n",
    "isofor.fit(full_pipeline.fit_transform(house_data))\n",
    "outliers = pd.DataFrame(isofor.predict(full_pipeline.fit_transform(house_data)), index=house_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get index in data of predicted outliers\n",
    "outlier_index = outliers[outliers[0] != 1].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data_new = house_data.drop(outlier_index,).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign y and X variables\n",
    "y = house_data_new.SalePrice\n",
    "X = house_data_new.drop(['SalePrice'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split X,y into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Different Models\n",
    "\n",
    " - Highest MSE:\n",
    " - 28261.97 with XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process training and test data\n",
    "X_train_piped = full_pipeline.fit_transform(X_train)\n",
    "X_test_piped = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K Fold Cross Validation Function\n",
    "\n",
    "def model_test_kfold(X,y, model, num_splits):\n",
    "    skf = StratifiedKFold(n_splits=num_splits, random_state=213, shuffle=False) #5 Split K Fold\n",
    "    \n",
    "    X_piped = full_pipeline.fit_transform(X) #Transform raw data\n",
    "    all_rmse = []\n",
    "    n = 1\n",
    "    for train_index, test_index in skf.split(X_piped, y):\n",
    "        print(\"Training Split \", n)\n",
    "        X_train, X_test = X_piped[train_index], X_piped[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        all_rmse.append(rmse)\n",
    "        print('RMSE: ', rmse)\n",
    "        print('Fold ', n, \" Complete\")\n",
    "        n = n +1\n",
    "    return np.mean(all_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Model Im happy with\n",
    "best_model = XGBRegressor(objective ='reg:squarederror', random_state=213,learning_rate = 0.13, n_estimators = 300)\n",
    "#model_test_kfold(X,y,XGBRegressor(objective ='reg:squarederror', random_state=213,learning_rate = 0.13, n_estimators = 300), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  10 out of  10 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,\n",
       "                                    reg_alpha=0, reg_lambda=1,\n",
       "                                    scale_pos_weight=1, seed=None, silent=None,\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=5,\n",
       "             param_grid={'learning_rate': [0.03, 0.05, 0.07, 0.1, 0.15],\n",
       "                         'n_estimators': [1000],\n",
       "                         'objective': ['reg:squarederror'],\n",
       "                         'random_state': [213]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "parameters = {'objective':['reg:squarederror'], 'random_state': [213],\n",
    "              'learning_rate': [.03, 0.05, .07, .1, .15], \n",
    "              'n_estimators': [1000]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "xgb_grid.fit(X_train_piped, y_train, \n",
    "             early_stopping_rounds=5, \n",
    "             eval_set=[(X_test_piped, y_test)], \n",
    "             verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform Test Data\n",
    "test_data_new = test_data.drop(['Id'], axis = 1,inplace = False)\n",
    "test_data_piped = full_pipeline.transform(test_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.13, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=300,\n",
       "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=213, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model to entire training data\n",
    "best_model.fit(full_pipeline.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Predictions\n",
    "y_pred = best_model.predict(test_data_piped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DF for final predictions\n",
    "final_preds = pd.DataFrame(columns = ['Id','SalePrice'])\n",
    "final_preds['Id'] = test_data['Id']\n",
    "final_preds['SalePrice'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = final_preds.to_csv (r'C:\\Users\\Isaac\\Desktop\\final_preds.csv', index = None, header=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Not Required to Run Cells  \n",
    "##  Mostly for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign numeric variables\n",
    "num_cols = [\"LotFrontage\",\"LotArea\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"GrLivArea\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"BedroomAbvGr\",\"TotRmsAbvGrd\",\"Fireplaces\",\"GarageCars\",\"GarageArea\",\"WoodDeckSF\",\"OpenPorchSF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Numeric Columns\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "X_train_new = num_pipeline.fit_transform(X_train[num_cols])\n",
    "X_test_new = num_pipeline.transform(X_test[num_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Categoric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect Nomial Columns to One Hot Encode\n",
    "OH_cols = set(X.columns) - set(num_cols) - set(all_ordinal_cols)\n",
    "OH_cols = list(OH_cols)\n",
    "#X_train[OH_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#Replace NAs\n",
    "si = SimpleImputer(strategy='constant')\n",
    "\n",
    "X_train[OH_cols] =si.fit_transform(X_train[OH_cols])\n",
    "X_test[OH_cols] = si.transform(X_test[OH_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OH Encode\n",
    "onehot = OneHotEncoder()\n",
    "\n",
    "OH_train = pd.DataFrame(\n",
    "    onehot.fit_transform(X_train[OH_cols].astype(str)).toarray())\n",
    "OH_test = pd.DataFrame(\n",
    "    onehot.fit_transform(X_test[OH_cols].astype(str)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all variables we OH encoded from original DataFrame\n",
    "X_train = X_train.drop(OH_cols, axis = 1)\n",
    "X_test = X_test.drop(OH_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Ordinal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns to binarize\n",
    "\n",
    "all_ordinal_cols = [\"OverallQual\",\"OverallCond\",\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"HeatingQC\",\"KitchenQual\", \"FireplaceQu\"]\n",
    "ord_cols = [\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"HeatingQC\",\"KitchenQual\", \"FireplaceQu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assign Order (OverallQual and OverallCond do not need to be converted as they are already 1-10)\n",
    "  \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# def orderizer(df,ord_cols, order_cats = ['missing', 'Po', 'Fa', 'TA', 'Gd','Ex']):\n",
    "#     for col in ord_cols:\n",
    "#         cat = pd.Categorical(df[col],\n",
    "#                             categories = order_cats,\n",
    "#                              ordered = True)\n",
    "#         cat = cat.fillna('missing')\n",
    "#         labels, unique = pd.factorize(cat, sort=True)\n",
    "#         df[col] = labels\n",
    "\n",
    "\n",
    "class NominalFixer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass  # e.g. pass in a column name to extract\n",
    "    \n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        def orderizer(df, order_cats = ['missing', 'Po', 'Fa', 'TA', 'Gd','Ex']):\n",
    "            for col in df.columns:\n",
    "                cat = pd.Categorical(df[col],\n",
    "                                    categories = order_cats,\n",
    "                                     ordered = True)\n",
    "                cat = cat.fillna('missing')\n",
    "                labels, unique = pd.factorize(cat, sort=True)\n",
    "                df[col] = labels\n",
    "        ord_df = orderizer(X)\n",
    "        return X  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing        \n",
    "        \n",
    "#Original For Code that was turned into above function\n",
    "#   for col in ordinal_encode_cols:\n",
    "#         cat = pd.Categorical(X_train[col],\n",
    "#                             categories = ['missing', 'Po', 'Fa', 'TA', 'Gd','Ex'],\n",
    "#                              ordered = True)\n",
    "#         cat = cat.fillna('missing')\n",
    "#         labels, unique = pd.factorize(cat, sort=True)\n",
    "#         X_train[col] = labels\n",
    "#         cat = pd.Categorical(X_test[col],\n",
    "#                             categories = ['missing', 'Po', 'Fa', 'TA', 'Gd','Ex'],\n",
    "#                              ordered = True)\n",
    "#         cat = cat.fillna('missing')\n",
    "#         labels, unique = pd.factorize(cat, sort=True)\n",
    "#         X_test[col] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model function, scoring method is RMSE\n",
    "def model_test(model, X_train = X_train_piped, X_test = X_test_piped):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove observations with abnormally high sale price\n",
    "upperlimit = np.mean(house_data_new.SalePrice)+(3*np.std(house_data_new.SalePrice))\n",
    "upperlimit_index = house_data_new.SalePrice[house_data_new.SalePrice > upperlimit].index\n",
    "house_data_new = house_data.drop(upperlimit_index,).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  102200.48082020735\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  53234.854000079125\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  44937.521143537044\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  41871.955740951256\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  35436.721030725785\n",
      "Fold  5  Complete\n",
      "model SVR - Linear tested\n",
      "55536.30654710012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  105698.21778161725\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  58751.72317267036\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  50459.27888777085\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  47438.320811267\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  40727.552978016305\n",
      "Fold  5  Complete\n",
      "model SVR - RBF tested\n",
      "60615.018726268354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  65126.041234746\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  34791.64035604636\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  33563.01979607442\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  44344.30004594599\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  29835.874012468816\n",
      "Fold  5  Complete\n",
      "model Logit tested\n",
      "41532.17508905632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  54069.86808141416\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  34162.59659729829\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  34537.74563194063\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  38191.79811653342\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  32342.447260901205\n",
      "Fold  5  Complete\n",
      "model Decision Tree tested\n",
      "38660.891137617546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  51261.18685767407\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  21590.739306533655\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  23396.905119822793\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  26884.438465233303\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  25009.7873426398\n",
      "Fold  5  Complete\n",
      "model Random Forest tested\n",
      "29628.61141838073\n",
      "Training Split  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  215885.06796064004\n",
      "Fold  1  Complete\n",
      "Training Split  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  170783.6230903836\n",
      "Fold  2  Complete\n",
      "Training Split  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  156343.94379632943\n",
      "Fold  3  Complete\n",
      "Training Split  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  157549.63887504788\n",
      "Fold  4  Complete\n",
      "Training Split  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  156587.56622955896\n",
      "Fold  5  Complete\n",
      "model MLP tested\n",
      "171429.96799039198\n",
      "Training Split  1\n",
      "RMSE:  54625.17481456565\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  21723.28028604457\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  20951.74196369522\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  41051.494201534566\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  22499.327878029533\n",
      "Fold  5  Complete\n",
      "model KNN tested\n",
      "32170.20382877391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  54643.40828546865\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  30606.429051284358\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  30868.30860970929\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  30016.578551521063\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  30152.55873954741\n",
      "Fold  5  Complete\n",
      "model Ada Boost tested\n",
      "35257.45664750615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  92692.39575788332\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  45215.87983743857\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  40600.96813945926\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  34417.167959924875\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  32611.298857709015\n",
      "Fold  5  Complete\n",
      "model Gaussian NB tested\n",
      "49107.54211048301\n",
      "Training Split "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "RMSE:  48503.205434867894\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  19604.895431696816\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  20578.578253020667\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  20488.26050064888\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  22757.19865273993\n",
      "Fold  5  Complete\n",
      "model Gradient Boosting tested\n",
      "26386.427654594834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Split  1\n",
      "RMSE:  48354.547450752005\n",
      "Fold  1  Complete\n",
      "Training Split  2\n",
      "RMSE:  19820.04695969139\n",
      "Fold  2  Complete\n",
      "Training Split  3\n",
      "RMSE:  20486.330514141984\n",
      "Fold  3  Complete\n",
      "Training Split  4\n",
      "RMSE:  22019.631429401084\n",
      "Fold  4  Complete\n",
      "Training Split  5\n",
      "RMSE:  22703.8021896678\n",
      "Fold  5  Complete\n",
      "model XGBoost tested\n",
      "26676.871708730854\n"
     ]
    }
   ],
   "source": [
    "#Test a bunch of different models to see whats best\n",
    "model_names = ['SVR - Linear','SVR - RBF', 'Logit', 'Decision Tree', 'Random Forest', 'MLP',\n",
    "               'KNN','Ada Boost', 'Gaussian NB',\n",
    "               'Gradient Boosting', 'XGBoost']\n",
    "models = [SVR(kernel = 'linear'), SVR(kernel = 'rbf'), LogisticRegression(), DecisionTreeRegressor(), RandomForestRegressor(), MLPRegressor(), KNeighborsRegressor(), \n",
    "          AdaBoostRegressor(), GaussianNB(), GradientBoostingRegressor(),\n",
    "          XGBRegressor(objective ='reg:squarederror')]\n",
    "\n",
    "\n",
    "result_list = []\n",
    "for i in range(len(models)):\n",
    "    result = model_test_kfold(X,y,models[i], 5)\n",
    "    print('model ' + model_names[i] + ' tested')\n",
    "    print(result)\n",
    "    result_list.append([model_names[i], result])\n",
    "model_test_results = pd.DataFrame(result_list, columns=['Model', 'RMSE']) #store results in a pretty dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
